\documentclass[12pt,a4paper,twoside]{article}

\input{preamble}

\begin{document}

\vspace*{3cm}

\begin{center}
    \Huge\textbf{\doctitle}\\
    \Large\textbf{\docsubtitle}
    \\\vspace*{5mm} 
    \large\today                            
\end{center} 

\vspace*{5mm}

\begin{figure}[!b]
    \centering
    \includegraphics[width = 0.25\textwidth]{../figures/BTH_logo_black.png}
\end{figure}

\newpage

This document contains a compilation of all suggested exercises for the course MS2505: Bayesian
statistics at Blekinge Institute of Technology\cite{TheCourse}.

\newpage
\section{Repetition}
Basic probability theory notation and terms: This can be trivial or you may need to refresh your memory on these
concepts. Note that some terms may be different names for the same concept. Explain each of the following terms with
one sentence:
\begin{itemize}
    \item probability
    \item probability mass
    \item probability density
    \item probability mass function (pmf)
    \item probability density function (pdf)
    \item probability distribution
    \item discrete probability distribution
    \item continuous probability distribution
    \item cumulative distribution function (cdf)
    \item likelihood
\end{itemize}

\section{Repetition Exercises 1}
\begin{enumerate}
    \item Suppose a new genetic test can detect a rare mutation with 95\% sensitivity and 99\%
    specificity. The mutation occurs in 1/1000 of the population. A person tests positive for
    the mutation.
    \begin{enumerate}[label=$\alph*)$]
        \item What is the prior probability that the person has the mutation?
        \item What is the likelihood of observing a positive test result given the person has
        the mutation?
        \item Compute the posterior probability that the person has the mutation given the positive
        test result.
    \end{enumerate}
    \item A pharmaceutical company is testing a new drug that works for some genetic subtypes of a
    disease. From previous studies, it is believed that 70\% of patients respond to the drug if they
    carry the genetic marker ($\theta$ = 1), and only 10\% of patients respond if they do not have
    the marker ($\theta$ = 0). Suppose 20\% of the population has the marker. A patient is given the
    drug and responds positively.
    \begin{enumerate}[label=$\alph*)$]
        \item Write down the prior probabilities for $\theta$ = 1 and $\theta$ = 0.
        \item Derive the likelihood of the observed response for each possible $\theta$.
        \item Compute the posterior probability that the patient has the genetic
    \end{enumerate}
    \item An online retailer is trying to model the probability that a customer will make a purchase
    based on their browsing behavior. Let $\theta$ denote the unknown probability that a visitor makes
    a purchase. Suppose the prior distribution of $\theta$ is $Beta(\alpha = 2, \beta = 3)$, and
    the retailer observes that 3 out of 10 visitors made purchases.
    \begin{enumerate}[label=$\alph*)$]
        \item Derive the posterior distribution of $\theta$.
        \item What is the expected value of $\theta$ under the posterior distribution?
        \item If the retailer observes an additional 2 purchases from 5 new visitors, update the
        posterior distribution and compute the new expected value of $\theta$.
    \end{enumerate}
    \item Suppose that if $\theta$ = 0, then $y$ follows a geometric distribution with success probability
    $p$ = 0.4, and if $\theta$ = 1, $y$ follows a negative binomial distribution with parameters $r$ = 2
    and $p$ = 0.3. Assume that $\Pr(\theta = 0) = 0.6$ and $\Pr(\theta = 1) = 0.4$.
    \begin{enumerate}[label=$\alph*)$]
        \item Derive the formula for the marginal probability mass function of $y$.
        \item Given y = 3, calculate $\Pr(\theta = 1|y = 3)$.
    \end{enumerate}
    \item Suppose y follows a binomial distribution for given n and unknown parameter $\theta$, where the
    prior distribution of $\theta$ is $Beta(\alpha, \beta)$. Find the marginal distribution of $y$.
\end{enumerate}

\section{Repetition exercises 2}
\begin{enumerate}
    \item A diagnostic test has a sensitivity (true positive) of 98\% and a specificity (true negative)
    of 95\%. The prevalence of the disease is 1 in 500. A person tests positive.
    \begin{enumerate}[label=\alph*)]
        \item Compute the prior probability that the person has the disease.
        \item Find the probability of observing a positive test result if the person does not have
        the disease.
        \item Using Bayes' theorem, calculate the posterior probability that the person has the
        disease given the positive test result.
    \end{enumerate}
    \item Suppose an online platform models the probability of users clicking on an ad. Let
    the prior distribution of the click-through rate $\theta$ be $Beta(2, 2)$. After observing
    8 clicks out of 20 impressions:
    \begin{enumerate}
        \item Derive the posterior distribution of $\theta$.
        \item Compute the posterior mean of $\theta$.
        \item Predict the probability of observing 5 clicks out of the next 10 impressions.
    \end{enumerate}
    \item Suppose $\theta$ has a prior $Beta(3, 5)$ and the observed data $y$ is modeled as 
    $Binomial(n = 10, \theta)$.
    \begin{enumerate}[label=\alph*)]
        \item Derive the marginal distribution of $y$.
        \item Compute the posterior distribution of $\theta$ if $y = 6$.
        \item Calculate the posterior predictive probability of $y = 8$ in a new trial.
    \end{enumerate}
    \item Consider a normal distribution with known variance $\sigma^2 = 4$. Suppose
    the prior distribution for the mean $\mu$ is $N(10, 9)$. After observing data
    $y = [12, 14, 11]$:
    \begin{enumerate}[label=\alph*)]
        \item Derive the posterior distribution of $\mu$.
        \item Compute the posterior predictive mean and variance of a new observation $\tilde{y}$.
        \item Find the probability that $\tilde{y} > 15$.
    \end{enumerate}
    \item Mark is deciding whether to take the highway or a backroad on his trip to a nearby town.
    He knows that the highway is usually faster, but sometimes it can be congested due to construction
    or accidents. Mark observes that there is heavy traffic reported on the highway, and he needs to
    determine if the congestion is a one-time event or if it will continue for the day. Based on the
    prior information and the observed traffic delay, Mark applies Bayesian decision theory to decide
    whether to take the highway or the backroad.
    \begin{enumerate}[label=\alph*)]
    \item Mark knows the following prior information:
    \begin{itemize}
        \item The prior probability of construction causing a delay on the highway is 10\%
        (i.e., $P(Construction) = 0.1$).
        \item  The probability of a delay being caused by an accident is therefore 90\%
        (i.e., $P(Accident) = 0.9$).
        \item The likelihood of observing the delay given that it is caused by construction
        is 75\% (i.e., $P(Delay | Construction) = 0.75$).
        \item The likelihood of observing the delay given that it is caused by an accident
        is 25\% (i.e., $P(Delay | Accident) = 0.25$).
    \end{itemize}
    Given this, Mark uses Bayes’ Theorem to update his belief about the likelihood of
    construction causing the delay. Derive the posterior probabilityof construction, given
    the observed delay.
    \item Mark has two choices:
    \begin{itemize}
        \item If Mark takes the backroad, the travel time is fixed at 60 minutes and the utility
        is 0.
        \item If Mark takes the highway:
        \begin{itemize}
            \item If there is construction (posterior probability 0.1), the delay is 45 minutes,
            and the utility is $-30$.
            \item If there is no construction (posterior probability 0.9), the travel time is
            15 minutes, and the utility is 10.
        \end{itemize}
    \end{itemize}
    Calculate the expected utility for both taking the highway and taking the backroad, and
    determine the optimal decision for Mark.
    \end{enumerate}
\end{enumerate}

\section{Old exam 2022-05-24}
\begin{enumerate}
    \item[1a)] What are the differences between the Bayesian and classical methods?
    \item[1b)] Explain how to perform diagnostic analysis in Bayesian models.
    \item[1c)] What is a hierarchical model? Give an example of when this type of model is useful. What is the
    issue with the applicability of this type of model?
    \item[1d)] What is a prior? Give examples of different types of priors and talk about their strengths and
    weaknesses.
    \item[2.] Lupus is an autoimmune disease, where antibodies attack plasma proteins instead of foreign cells.
    It is believed that 2\% of the population has this condition. Suppose that the exam to detect Lupus has 98\%
    accuracy when the patient has the disease and 74\% when (s)he does not have the condition.
    \begin{enumerate}[label=\textbf{2\alph*)}]
        \item What theorem is involved in this type of problem?
        \item What is the probability that the patient has Lupus when the result is positive?
    \end{enumerate}
    \item[3.] Suppose that if $\theta = 0$, then $y$ follows a normal distribution with mean 3 and variance $\sigma^2$,
    and if $\theta = 1$, then $y$ has a normal distribution with mean 4 and variance $\sigma^2$. Assuming that
    $P(\theta = 0) = 0.3$, $P(\theta = 1) = 0.7$, and $\sigma = 2$:
    \begin{enumerate}[label=\textbf{3\alph*)}]
        \item Write the formula for the marginal probability density for $y$.
        \item What is $P(\theta = 1 \mid y = 1)$?
    \end{enumerate}
    \item[4.] Hemophilia is a disease that exhibits X-chromosome-linked recessive inheritance that is fatal for women who
    inherit two such genes. Since human males have one X-chromosome and one Y-chromosome, whereas females have two X-chromosomes
    (one inherited from each parent), a female carrying the gene on only one of her two X-chromosomes is not affected.
    
    Consider a woman who has an affected brother, which implies that her mother must be a carrier of the hemophilia gene
    (with one “good” and one “bad” hemophilia gene). We are also told that her father is not affected; thus, the woman herself
    has a fifty-fifty chance of having the gene. The unknown quantity of interest, the state of the woman, has just two values:
    the woman is either a carrier of the gene ($\theta = 1$) or not ($\theta = 0$). Suppose she has three sons, none of whom are
    affected. Let $y_i = 1$ or $0$ denote an affected or unaffected son, respectively. The outcomes of the three sons are
    exchangeable, and conditional on the unknown $\theta$, are independent. We assume the sons are not identical triples.
    \begin{enumerate}[label=\textbf{4\alph*)}]
        \item What is the prior distribution for the unknown $\theta$?
        \item What is the likelihood function of the three independent data?
        \item What is the posterior probability that the woman is a carrier?
        \item Supposing that the woman has a fourth son, who is also unaffected, what is the posterior probability that the woman
        is a carrier?
    \end{enumerate}
    \item[5.] Suppose $y$ follows a binomial distribution for a given $n$ and unknown parameter $\theta$, where the prior distribution
    of $\theta$ is Beta$(\alpha, \beta)$. Find the marginal distribution of $y$.
    \item[6.] A 45-year-old man has a tumor that is malignant with an 80\% probability. Based on statistics:
    \begin{itemize}
        \item Expected lifetime is 30 years if no cancer.
        \item Expected lifetime is 10 years if cancer and radiation therapy are used.
        \item Expected lifetime is 25 years if cancer and surgery, but the probability of dying in surgery is 50\% (risky surgery).
        \item Expected lifetime is 4 years if cancer and no treatment.
    \end{itemize}
    Which treatment should be chosen to aim at having a quality-adjusted lifetime? Note that 3 years are subtracted from the time
    spent in treatments.
\end{enumerate}

\section{Book exercises}
The following exercises are from the MS2505 course book\cite{CourseBook}. Follow the cite in each question for the pages
the exercise is at in the book.
\begin{enumerate}
    \item[1.1] Conditional probability: suppose that if $\theta = 1$, then $y$ has a normal distribution with mean
    1 and standard deviation $\alpha$, and if $\theta = 2$, then $y$ has a normal distribution with mean 2
    and standard deviation $\alpha$. Also, suppose $\Pr(\theta = 1) = 0.5$ and $\Pr(\theta = 2) = 0.5$\cite{Chapter1Exercises}.
    \begin{enumerate}[label=$\alph*)$]
        \item For $\alpha = 2$, write the formula for the marginal probability density for $y$ and sketch it.
        \item What is $\Pr(\theta = 1|y = 1)$, again supposing $\alpha = 2$?
        \item Describe how the posterior density of $\theta$ changes in shape as $\alpha$ is increased and as it is
        decreased.
    \end{enumerate}
    \item[1.4] We will use the football dataset to estimate some conditional probabilities about professional football
    games. There were twelve games with point spreads of 8 points; the outcomes in those games were: -7, -5, -3, -3,
    1, 6, 7, 13, 15, 16, 20 and 21, with positive values indicating wins by the favorite and negative values indicating
    wins by the underdog. Consider the following conditional probabilities\cite{Chapter1Exercises}:
    \begin{itemize}
        \item $\Pr(\text{favorite wins }|\text{ point spread }= 8)$,
        \item $\Pr(\text{favorite wins by at least }8\text{ }|\text{ point spread }= 8)$,
        \item $\Pr(\text{favorite wins by at least }8\text{ }| \text{ point spread } = 8\text{ and favorite wins})$.
    \end{itemize} 
    \item[1.6] Approximately $\frac{1}{125}$ of all births are fraternal twins and $\frac{1}{300}$ of births are identical twins.
    Elvis Presley had a twin brother (who died at birth). What is the probability that Elvis was an identical twin?
    (You may approximate the probability of a boy or girl birth as $\frac{1}{2}$)\cite{Chapter1Exercises}.
    \item[2.1] Suppose you have a $Beta(4, 4)$ prior distribution on the probability $\theta$ that a coin will yield a \textit{head} when
    spun in a specified manner. The coin is independently spun ten times, and \textit{heads} appear fewer than 3 times. You are not
    told how many heads were seen, only that the number is less than 3. Calculate your exact posterior density (up to a proportionality
    constant) for $\theta$ and sketch it\cite{Chapter2Exercises}.
    \item[2.4] Let $y$ be the number of 6's in $1000$ independent rolls of a particular real die, which may be unfair. Let $\theta$ be the
    probability that the die lands on \textit{6}. Suppose your prior distribution for $\theta$ is as follows\cite{Chapter2Exercises}:
    \begin{itemize} 
        \item $\Pr(\theta = 1/12) = 0.25$,
        \item $\Pr(\theta = 1/6) = 0.5$,
        \item $\Pr(\theta = 1/4) = 0.25$.
    \end{itemize}
    Using the normal approximation for the conditional distributions, $p(y|\theta)$, sketch your approximate prior predictive distribution
    for $y$.
    \item[2.5] Posterior distribution as a compromise between prior information and data: let $y$ be the number of heads in n spins of a coin,
    whose probability of heads is $\theta$\cite{Chapter2Exercises}.
    \begin{enumerate}[label=$\alph*)$]
        \item If your prior distribution for $\theta$ is uniform on the range [0, 1], derive your prior predictive distribution for $y$,
        \[
        \Pr(y = k) = \int_{0}^{1} \Pr(y = k|\theta) d\theta, k = 0, 1, . . . , n.
        \]
        \item Suppose you assign a $Beta(\alpha, \beta)$ prior distribution for $\theta$, and then you observe $y$ heads
        out of $n$ spins. Show algebraically that your posterior mean of $\theta$ always lies between your prior mean,
        $\frac{\alpha}{\alpha + \beta}$, and the observed relative frequency of heads, $\frac{y}{n}$.
    \end{enumerate}
    \item[2.8] A random sample of $n$ students is drawn from a large population, and their weights are measured. The
    average weight of the $n$ sampled students is $y = 150$ pounds. Assume the weights in the population are
    normally distributed with unknown mean $\theta$ and known standard deviation 20 pounds. Suppose your prior
    distribution for $\theta$ is normal with mean 180 and standard deviation 40\cite{Chapter2Exercises}.
    \begin{enumerate}[label=$\alph*)$]
        \item Give your posterior distribution for $\theta$. (Your answer will be a function of $n$.)
        \item A new student is sampled at random from the same population and has a weight of $\tilde{y}$ pounds.
        Give a posterior predictive distribution for $\tilde{y}$. (Your answer will still be a function of $n$.)
        \item For $n = 10$, give a 95\% posterior interval for $\theta$ and a 95\% posterior predictive interval
        for $\tilde{y}$.
        \item Do the same for $n = 100$.
    \end{enumerate}
    \item[2.16] Suppose y has a binomial distribution for a given $n$ and unknown parameter $\theta$, where the prior
    distribution of $\theta$ is $Beta(\alpha, \beta)$. Find $p(y)$, the marginal distribution of $y$, for $y = 0,
    \dots, n$ (unconditional on $\theta$). This discrete distribution is known as the beta-binomial, for obvious
    reasons\cite{Chapter2Exercises}.
    \item[3.3] An experiment was performed on the effects of magnetic fields on the flow of calcium out of chicken brains.
    Two groups of chickens were involved: a control group of 32 chickens and an exposed group of 36 chickens. One measurement
    was taken on each chicken, and the purpose of the experiment was to measure the average flow $\mu_c$ in untreated (control)
    chickens and the average flow µt in treated chickens. The 32 measurements on the control group had a sample mean of $1.013$
    and a sample standard deviation of $0.24$. The 36 measurements on the treatment group had a sample mean of $1.173$ and a
    sample standard deviation of $0.20$.

    Assuming the control measurements were taken at random from a normal distribution with mean $\mu_c$ and variance $\sigma^{2}_{c}$,
    what is the posterior distribution of $\mu_c$? Similarly, use the treatment group measurements to determine the marginal posterior
    distribution of $\mu_t$. Assume a uniform prior distribution on ($\mu_c$, $\mu_t$, $\log(\sigma_c)$, $\log(\sigma_t)$)\cite{Chapter3Exercises}.
    \item[3.5] Rounded data: it is a common problem for measurements to be observed in rounded form (for a review, see Heitjan, 1989).
    For a simple example, suppose we weigh an object five times and measure weights, rounded to the nearest pound, of 10, 10, 12, 11,
    9. Assume the unrounded measurements are normally distributed with a noninformative prior distribution on the mean $\mu$ and
    variance $\sigma^2$\cite{Chapter3Exercises}.
    \begin{enumerate}[label=$\alph*)$]
        \item Give the posterior distribution for $(\mu, \sigma^2)$ obtained by pretending that the observations are exact unrounded
        measurements.
        \item Give the correct posterior distribution for $(\mu, \sigma^2)$ treating the measurements as rounded.
    \end{enumerate}
    \item[3.9] Suppose $y$ is an independent and identically distributed sample of size $n$ from the distribution $N(\mu, \sigma^2)$, where the
    prior distribution for $(\mu, \sigma^2)$ is $N-Inv-\chi^2(\mu, \sigma^2|\mu_0, \frac{\sigma^2_0}{\kappa_0}; v_0, \sigma^{2}_{0})$; that is,
    $\sigma^2 ~ Inv-\chi^2(v_0, \sigma^2_0)$ and $\mu|\sigma^2 ~ N(\mu_0, \sigma^2/\kappa_ 0)$. The posterior distribution, $p(\mu, \sigma^2|y)$,
    is also normal-inverse-$\chi^2$; derive explicitly its parameters in terms of the prior parameters and the sufficient statistics of the
    data\cite{Chapter3Exercises}.
    \item[4.2] Derive the analytic form of the information matrix and the normal approximation variance for the bioassay
    example\cite{BioassayExample}\cite{Chapter4Exercises}.
    \item[4.4] Asymptotic normality: assuming the regularity conditions hold, we know that $p(\theta|y)$ approaches normality as $n \rightarrow \infty$.
    In addition, if $\Phi = f(\theta)$ is any one-to-one continuous transformation of $\theta$, we can express the Bayesian inference in terms of
    $\Phi$ and find that $p(\Phi|y)$ also approaches normality. But a nonlinear transformation of a normal distribution is no longer normal. How
    can both limiting normal distributions be valid\cite{Chapter4Exercises}?
    \item[4.13] Discuss the criticism, "Bayesianism assumes: (a) Either a weak or uniform prior [distribution], in which case why bother?, (b) Or a
    strong prior [distribution], in which case why collect new data?, (c) Or more realistically, something in between, in which case Bayesianism
    always seems to duck the issue" (Ehrenberg, 1986). Feel free to use any of the examples covered so far to illustrate your points.
    \item[5.4] Exchangeable prior distributions: suppose it is known a priori that the 2J parameters $\theta_1,\dots, \theta_{2J}$ are clustered
    into two groups, with exactly half being drawn from a $N(1, 1)$ distribution, and the other half being drawn from a $N(-1, 1)$ distribution,
    but we have not observed which parameters come from which distribution.
    
    Are $\theta_1,\dots, \theta_{2J}$ exchangeable under this prior distribution?
    \item[5.7] If $y|\theta ~ Poisson(\theta)$, and $\theta ~ Gamma(\alpha, \beta)$, then the marginal (prior predictive) distribution of $y$ is
    negative binomial with parameters $\alpha$ and $\beta$ (or $p = \beta/(1 + \beta)$). Use the formulas (2.7)\footnote{$E(\theta) = E(E(\theta|y))$}
    and (2.8)\footnote{$var(\theta) = E(var(\theta|y)) + var(E(\theta|y))$} to derive the mean and variance of the negative binomial.
    \item[5.11] Suppose that in the rat tumor example, we wish to use a normal population distribution on the log-odds scale:
    \[
    logit(\theta_j ) ~ N(\mu, \tau^2),for j = 1,\dots, J.
    \]
    As in Section 5.3, you will assign a noninformative prior distribution to the hyperparameters and perform a full Bayesian analysis.
    
    Write the joint posterior density, $p(\theta, \mu, \tau|y)$. 
\end{enumerate}

\newpage

\bibliographystyle{unsrt}
\bibliography{lib}

\end{document}